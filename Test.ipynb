{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/14MKnDfgWExFIcRbsdz65XeN-Nb-goUL6#scrollTo=sYyTIPLsvMWl)"
      ],
      "metadata": {
        "id": "U8XOlgbq9dTV"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYyTIPLsvMWl",
        "cellView": "code"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzwiVqbcmJIX",
        "cellView": "code"
      },
      "source": [
        "import ee\n",
        "ee.Authenticate()\n",
        "ee.Initialize()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "WjOh_CJeyy2m"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/adugnag/S1-S2_Transformer/main/helper.py\n",
        "\n",
        "from helper import s1_preproc, get_s2_sr_cld_col, apply_cld_shdw_mask, add_cld_shdw_mask, NBRaddTimeline,export_test_image, prepTestData, writeTfrecord\n",
        "import json\n",
        "import numpy as np\n",
        "from pprint import pprint"
      ],
      "metadata": {
        "id": "hd3zOgmBEyks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RZRRzcfVu5T"
      },
      "source": [
        "#parameters\n",
        "params = {  'START_DATE': '2019-01-01', \n",
        "            'STOP_DATE': '2020-12-31',        \n",
        "            'ORBIT': 'DESCENDING',\n",
        "            'RELATIVE_ORBIT_NUMBER': 'ANY', \n",
        "            'SATELLITE': 'ANY',\n",
        "            'POLARIZATION': 'VVVH',\n",
        "            'ROI': ee.Geometry.Polygon([[[-62.407, -18.249],[-62.407, -18.452],[-62.174, -18.452],[-62.174, -18.249]]]),\n",
        "            'DEM': ee.Image('USGS/SRTMGL1_003'),\n",
        "            'APPLY_BORDER_NOISE_CORRECTION': True,\n",
        "            'APPLY_TERRAIN_FLATTENING': False,\n",
        "            'TERRAIN_FLATTENING_MODEL': 'VOLUME',\n",
        "            'TERRAIN_FLATTENING_ADDITIONAL_LAYOVER_SHADOW_BUFFER':0,\n",
        "            'APPLY_SPECKLE_FILTERING': True,\n",
        "            'SPECKLE_FILTER_FRAMEWORK':'MULTI',\n",
        "            'SPECKLE_FILTER': 'BOXCAR',\n",
        "            'SPECKLE_FILTER_KERNEL_SIZE': 15,\n",
        "            'NR_OF_IMAGES':10,\n",
        "            'FORMAT': 'DB',\n",
        "            'CLIP_TO_ROI': False,\n",
        "            'interval':30,\n",
        "            'increment':'day',\n",
        "            'BANDS1' :['VV','VH'],\n",
        "            'BANDS2' : ['NBR'],\n",
        "            'DATA_BUCKET':'senalerts_dl4',\n",
        "            'OUTPUT_BUCKET':'senalerts_dl4',\n",
        "            'FOLDER':'TDF1',\n",
        "            'MODEL_NAME':'TDF_MHSA_PAR_S1_S2_v2',\n",
        "            'IMAGE_FILE_PREFIX1' : 'TDF_TEST_PAR_S1_v0_',\n",
        "            'IMAGE_FILE_PREFIX2' : 'TDF_TEST_PAR_S2_v0_',\n",
        "            'NUM_S1':25,\n",
        "            'NUM_S2':25,\n",
        "            'OUT_IMAGE_NAME':'TDF_TEST_PAR_S1_S2_Transformer_v4_.TFRecord',\n",
        "            'OUT_ASSET_NAME': 'TDF_PAR_S1_S2_Transformer_v4_'\n",
        "            }\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_DIR = 'gs://' + params['DATA_BUCKET'] + '/' + params['FOLDER'] + '/' + params['MODEL_NAME']\n",
        "#custom_objects = {'TransformerBlock':TransformerBlock,'PositionalEmbedding':PositionalEmbedding}\n",
        "hypermodel = tf.keras.models.load_model(MODEL_DIR) \n",
        "hypermodel.summary()"
      ],
      "metadata": {
        "id": "LWp1cZAvdS1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#process Sentinel 1 image collection\n",
        "s1_processed = s1_preproc(params)\n",
        "s1_processed = s1_processed.select(['VV','VH'])\n",
        "s1_nr = s1_processed.size().getInfo()\n",
        "print('Number of images in the collection: ', s1_processed.size().getInfo())\n",
        "\n",
        "#apply a moving median smoothing over the time-series\n",
        "startDate = ee.Date(params['START_DATE']);\n",
        "secondDate = startDate.advance(params['interval'], params['increment']).millis();\n",
        "increase = secondDate.subtract(startDate.millis());\n",
        "LIST1 = ee.List.sequence(startDate.millis(), ee.Date('2020-12-31').millis(), increase);\n",
        "\n",
        "def mov_s1(date):\n",
        "  return s1_processed.filterDate(ee.Date(date), ee.Date(date).advance(params['interval'], params['increment'])) \\\n",
        "           .median().set('system:time_start',ee.Date(date).millis())\n",
        "\n",
        "#smoothened collection\n",
        "collection1 =  ee.ImageCollection.fromImages(LIST1.map(mov_s1));\n",
        "\n",
        "#convert the collection to a single image\n",
        "image1 = collection1.toArrayPerBand()\n",
        "\n",
        "#Select image to display\n",
        "image_S1 = collection1.first()\n",
        "print('Number of images in the smoothened S1 collection: ', collection1.size().getInfo())\n",
        " "
      ],
      "metadata": {
        "id": "1WqRAONYg_WG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sentinel-2 ts processing\n",
        "\n",
        "s2_sr_cld_col = get_s2_sr_cld_col(params['ROI'], params['START_DATE'], params['STOP_DATE'])\n",
        "s2_sr = s2_sr_cld_col.map(add_cld_shdw_mask).map(apply_cld_shdw_mask)\n",
        "s2_sr = s2_sr.map(NBRaddTimeline).select('NBR')\n",
        "\n",
        "print('Number of images in the original collection: ', s2_sr.size().getInfo())\n",
        "\n",
        "#S2 time-series smoothing\n",
        "def mov_s2(date):\n",
        "  return s2_sr.filterDate(ee.Date(date), ee.Date(date).advance(params['interval'], params['increment'])) \\\n",
        "           .median().set('system:time_start',ee.Date(date).millis())\n",
        "\n",
        "#apply time series smoothing\n",
        "collection2 =  ee.ImageCollection.fromImages(LIST1.map(mov_s2));\n",
        "\n",
        "image2 = collection2.toArrayPerBand()\n",
        "s2_nr = s2_sr.size().getInfo()\n",
        "print('Number of images in the smoothened S2 collection: ', collection2.size().getInfo())"
      ],
      "metadata": {
        "id": "toSL9niMhA3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYmH_wCOUhIv"
      },
      "source": [
        "#feature maps for exporting the time series data\n",
        "fmap1 = dict(zip(list(params['BANDS1']), np.repeat(params['NUM_S1'],len(params['BANDS1'])).tolist()))\n",
        "fmap2 = dict(zip(list(params['BANDS2']), np.repeat(params['NUM_S2'],len(params['BANDS2'])).tolist()))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#export the test images\n",
        "\n",
        "export_test_image(fmap1,image1,params['IMAGE_FILE_PREFIX1'])\n",
        "export_test_image(fmap2,image2,params['IMAGE_FILE_PREFIX2'])"
      ],
      "metadata": {
        "id": "I0-JoIEKxXBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Utility functions (RUN)\n",
        "def listFiles(IMAGE_FILE_PREFIX, OUTPUT_BUCKET):\n",
        "  files_list1 = !gsutil ls 'gs://'{OUTPUT_BUCKET}\n",
        "  # Get only the files generated by the image export.\n",
        "  exported_files_list1 = [s for s in files_list1 if IMAGE_FILE_PREFIX in s]\n",
        "\n",
        "  # Get the list of image files and the JSON mixer file.\n",
        "  image_files_list1 = []\n",
        "  json_file1 = None\n",
        "  for f in exported_files_list1:\n",
        "    if f.endswith('.tfrecord.gz'):\n",
        "      image_files_list1.append(f)\n",
        "    elif f.endswith('.json'):\n",
        "      json_file1 = f\n",
        "\n",
        "  # Make sure the files are in the right order.\n",
        "  image_files_list1.sort()\n",
        "  return image_files_list1, json_file1\n",
        "\n",
        "def getMixer(json_file):\n",
        "  json_text = !gsutil cat {json_file}\n",
        "  # Get a single string w/ newlines from the IPython.utils.text.SList\n",
        "  mixer = json.loads(json_text.nlstr)\n",
        "\n",
        "  return mixer"
      ],
      "metadata": {
        "id": "BdrXti8YLBAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "image_files_list1, json_file1 = listFiles(params['IMAGE_FILE_PREFIX1'], params['OUTPUT_BUCKET'])\n",
        "image_files_list2, json_file2 = listFiles(params['IMAGE_FILE_PREFIX2'], params['OUTPUT_BUCKET'])\n",
        "\n",
        "pprint(image_files_list1)\n",
        "print(json_file1)\n",
        "\n",
        "pprint(image_files_list2)\n",
        "print(json_file2)"
      ],
      "metadata": {
        "id": "pDj2eATXpu_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get the mixer\n",
        "mixer1 = getMixer(json_file1)\n",
        "mixer2 = getMixer(json_file2)\n",
        "\n",
        "print(mixer1)\n",
        "print(mixer2)"
      ],
      "metadata": {
        "id": "ubnWagb62hMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Preparte the test Sentinel-1 and Sentinel-2 dataset in  tf.data.Dataset format\n",
        "image_dataset1 = prepTestData(mixer1,params['BANDS1'],image_files_list1, params['NUM_S1'])\n",
        "image_dataset2 = prepTestData(mixer2,params['BANDS2'],image_files_list2, params['NUM_S2'])"
      ],
      "metadata": {
        "id": "OZ6-JQPW8cM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generator():\n",
        "  for s1, s2 in zip(image_dataset1, image_dataset2):\n",
        "    yield {\"input_5\": s1, \"input_6\": s2}\n",
        "\n",
        "#Combined Sentinel-1 and 2 datasets\n",
        "dataset = tf.data.Dataset.from_generator(generator, output_types=({\"input_5\": tf.float32, \"input_6\": tf.float32}))\n",
        "\n",
        "#check both data branches\n",
        "pprint(iter(dataset).next())"
      ],
      "metadata": {
        "id": "unrVdQvjnctD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run prediction in batches, with as many steps as there are patches.\n",
        "predictions = hypermodel.predict(dataset, steps=mixer2['totalPatches'], verbose=1)\n",
        "\n",
        "# Note that the predictions come as a numpy array.  Check the first one.\n",
        "print(predictions[0])\n",
        "\n",
        "print(predictions.shape)"
      ],
      "metadata": {
        "id": "WXhhSkeDMlhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_IMAGE_FILE = 'gs://' + params['OUTPUT_BUCKET'] + '/' + params['FOLDER'] + '/' + params['OUT_IMAGE_NAME']\n",
        "OUTPUT_ASSET_ID ='users/adugnagirma' + '/' + params['OUT_ASSET_NAME']\n",
        "\n",
        "writeTfrecord(OUTPUT_IMAGE_FILE,OUTPUT_ASSET_ID, predictions, mixer1)\n",
        "\n",
        "#Upload to GEE\n",
        "!earthengine upload image --asset_id={OUTPUT_ASSET_ID} --pyramiding_policy=mode {OUTPUT_IMAGE_FILE} {json_file1}"
      ],
      "metadata": {
        "id": "u8KwfrP5tjUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Upload to GEE\n",
        "#OUTPUT_ASSET_ID = 'users/adugnagirma' + '/TDF_PAR_S1_S2_Transformer_v2_'\n",
        "!earthengine upload image --asset_id={OUTPUT_ASSET_ID} --pyramiding_policy=mode {OUTPUT_IMAGE_FILE} {json_file1}"
      ],
      "metadata": {
        "id": "JDiCM9Hwfx2e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
